{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Predicting Housing Prices with Linear Regression ðŸ¡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Understanding and Applying Linear Regression \n",
    "* Data Exploration\n",
    "* Practice ML Workflow: Training, Testing, and Evaluation\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Implementing Linear Regression](#1.-Implementing-Linear-Regression)\n",
    "2. [Finding a House in Boston](#2.-Finding-a-House-in-Boston)\n",
    "3. [Exploring the Data](#3.-Exploring-the-Data)\n",
    "4. [Training the Model](#4.-Training-the-Model)\n",
    "    1. [Making Training and Test Datasets](#Making-Training-and-Test-Datasets)\n",
    "    2. [Regression on Boston Housing data](#Regression-on-Boston-Housing-data)\n",
    "5. [Analyzing Model Performance](#5.-Analyzing-Model-Performance)\n",
    "    1. [Root Mean Squared Error (RMSE)](#Root-Mean-Squared-Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's Lab\n",
    "\n",
    "In this lab, you will build your first intelligent application that makes predictions from data. We will explore this idea within the context of our first case study, predicting house prices, where you will create models that predict a continuous value (price) from input features (square footage, number of bedrooms and bathrooms, etc.). This is just one of the many places where regression can be applied. Other applications range from predicting health outcomes in medicine, stock prices in finance, and power usage in high-performance computing, to analyzing which regulators are important for gene expression. You will also examine how to analyze the performance of your predictive model and implement regression in practice using an iPython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Regression?\n",
    "\n",
    "Let's start our discussion with the idea of **regression** itself. It's [Wikipedia article](https://en.wikipedia.org/wiki/Regression_analysis) starts with this:\n",
    "\n",
    "> In statistical modeling, regression analysis is a set of statistical processes for estimating the relationships among variables.\n",
    "\n",
    "The goal is to take a set of predictor variables, or _features_, and figure out how they contribute to the phenomenon we are interested. Again from Wikipedia, regression\n",
    "\n",
    "> helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the [predictor] independent variables is varied while the others...are held fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is typically achieved by combining features with a **model**, a simple representation of the relationships between features. In the case of linear regression, we use a **linear model**, $$y = wx + b,$$ which combines the features, $x$, after weighting each by their significance, $w$, and adding a bias value, $b$, to compute the predicted value, $y$. In this case, $d$ is the number of features we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put (slightly more) simply, **linear regression** tries to model the relationship between features and a phenomenon variable by fitting a line to observed data. ![Linear Regression](utility/pics/linear-regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Implementing Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start working on the Boston housing data set, we will first use the toy dataset from class to develop and test our code. The dataset is stored in a `txt` file so we have to import it first. Using this small toy dataset, we will implement a simple linear regression model that use $x$ as predictor and $y$ as target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x, y = np.loadtxt('utility/data/toy_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16,9]\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deriving Model Parameters\n",
    "\n",
    "Recall the derivation of $w$ and $b$ from lecture minimizing the sum of squared error, also residual sum of squares (RSS), with slight rearrangement:\n",
    "\n",
    "\n",
    "$$b = \\displaystyle \\frac{1}{n} \\sum_{n=1}^n y_i - w \\frac{1}{n} \\sum_{n=1}^n x_i $$\n",
    "\n",
    "and\n",
    "\n",
    "$$w = \\frac{\\displaystyle\\sum_{n=1}^n x_iy_i - \\frac{1}{n} \\sum_{n=1}^n x_i \\sum_{n=1}^n y_i}{\\displaystyle\\sum_{n=1}^n x_i^2 - \\frac{1}{n} \\sum_{n=1}^n x_i \\sum_{n=1}^n x_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Regression Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement these formulas. Do **not** use for loops!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Next, implement `compute_weights`. This function computes the optimal $w$ for a given data set $\\mathcal{D} = (X, y)$. Refer back to the derivation from above. Assign the result of your computation to the variable `w`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights(x, y):\n",
    "    '''computes the weights of the linear model that fits the data X and Y'''\n",
    "    \n",
    "    assert x.shape == y.shape, 'dimensions of X and Y should match in 1D linear regression'\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Next, implement `fit`. This function computes the best-fitting model parameters $w$ and $b$. Refer back to the derivation from above. Assign the result of your computation to variables `w` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y):\n",
    "    '''computes model parameters W and B that best-fit observation data X and Y'''\n",
    "    \n",
    "    assert x.shape == y.shape, 'dimensions of X and Y should match in 1D linear regression'\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    assert np.isscalar(w) and np.isscalar(b), 'W and B should be scalars in 1D linear regression'\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Finally, implement `predict`. This function computes the predicted values of the model given $w$, $b$, and points $x$. Refer back to the derivation from above. Assign the result of your computation to variables `w` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, x):\n",
    "    '''computes the predicted values of X given model parameters W and B'''\n",
    "    \n",
    "    assert np.isscalar(w) and np.isscalar(b), 'W and B should be scalars in 1D linear regression'\n",
    "    if not isinstance(x, int):\n",
    "        assert len(x.shape) == 1, 'X should be an int or n x 1 array'\n",
    "    \n",
    "    # your code here\n",
    "\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your implementation you can use our example from the lecture. My house, which has 1500sqft should be worth $359k (rounded). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = fit(x, y)\n",
    "\n",
    "x_myhouse = 1500\n",
    "y_myhouse = predict(w, b, x_myhouse)\n",
    "\n",
    "print(f'My house is worth ${y_myhouse:0.0f},000.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Regression Model (Fitted Line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try visualizing our model! But before that, run the following cell to configure our plots to be larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.util import configure_plots\n",
    "\n",
    "configure_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to start plotting. But, what does it mean to plot our model?\n",
    "\n",
    "Any mathematical function, like our model, is defined by its value at all points in the input domain, or the space. For example, if our model [maps](https://en.wikipedia.org/wiki/Map_(mathematics)) an independent variable to a dependent one (in the 1D case),\n",
    "\n",
    "$$f: x \\mapsto y,$$\n",
    "\n",
    "which is read function $f$ maps $x$ to $y$, then the $f$ is defined by all of the $y$ values it takes given all of the possible $x$ values. More concretely, if our input is \"square footage\" and our output is \"price,\" then our model takes the shape of \"prices\" for all possible \"square footage\" values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is not possible (tractable) to evaluate the function at all possible inputs â€” there are infinitely many of them for continuous variables. Instead, we evaluate the function at a \"grid\" of inputs. In one dimension, this would be a set of evenly spaced points. In 2D, this would be a grid. In higher dimensions, you can think of this as a lattice or a hyperlattice of points.\n",
    "\n",
    "We can evaluate our function (model) at all points in this grid by making predictions for each point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Create a one-dimensional \"grid\" of 1000 points that we can evaluate our function on. Store this grid in `x_star`, $x_*$. Think about what range of values to use if we suppose that $x$ is \"size in square feet\" and $y$ is \"price\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Now use `predict` to make predictions for `x_star`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model's predicted values (function values) at each point in our grid, we can start plotting.\n",
    "\n",
    "**Try this!** First, create a scatter plot of the training points. Then, using the [`plt.plot` ðŸ”—](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html) function to plot the evaluated model predictions. We'll take care of the rest of the plot components (axes labels, title, etc.) for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "plt.title('LM of Toy Data')\n",
    "plt.xlabel(\"Size in sq. ft.\")\n",
    "plt.ylabel(\"Price in 1k USD\")\n",
    "plt.legend(['Training data', 'Model'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty nifty! ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding a House in Boston\n",
    "\n",
    "I hear that you're trying to find a house in Boston! As excited as you are to go look at some houses, I bet the data scientist inside you can't resist the urge to do some good-ol' market research first.\n",
    "\n",
    "Okay, so maybe you're not looking to find a house in Boston, but there are many people who are interested in understanding the housing market there. More and more, professionals in various industries are turning to data science to better understanding trends in their fields. Let's give it a shot!\n",
    "\n",
    "![boston housing](utility/pics/boston-homes.jpg)\n",
    "Image sourced from [Boston Magazine](https://www.bostonmagazine.com/property/2014/11/06/open-houses-11-7/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing the Problem\n",
    "\n",
    "As we discussed in Lab 1, the data science workflow we will follow in this class begins with developing a question. For this example, let's go with this:\n",
    "\n",
    "> _Can we identify any patterns and trends in the Boston housing market? And, if so, can we build a model to predict the price of a house given some of its specs?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** What other kinds of questions would be interesting to ask about this dataset? Discuss with your neighbors and record your discussion in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your response here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acquiring the Data\n",
    "\n",
    "In the field, you will often have to collect and process the data you need on your own. In this case, however, we will be using data that has already been collected and cleaned. The cell below downloads the dataset hosted by [Scikit Learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston() \n",
    "\n",
    "# check if dataset is correctly loaded\n",
    "print(f'''The loaded dataset contains\n",
    "    {boston.data.shape[0]} observations and\n",
    "    {boston.data.shape[1]} features per observation.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our raw data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHOA. This looks crazy! Let's try to better understand our data by looking at its components. Luckily, a lot of this data is already organized for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Things in Order\n",
    "\n",
    "The dataset for this project originates from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). The Boston housing data was collected in 1978 and each of the 506 entries represent aggregated data about 14 features for homes from various suburbs in Boston, Massachusetts. Run the cell blow to see the names and a short description for each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take this data and put it into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(boston.data)\n",
    "y = np.array(boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Evaluate `X` and `y` to see what they look like. Also, try checking their shapes. What do the values correspond to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring the Data\n",
    "After the dataset is loaded, we will make a cursory investigation about the Boston housing data and provide your observations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(16, 16))\n",
    "f.subplots_adjust(hspace=0.6)\n",
    "\n",
    "# visualize the relationship of all varaibles and the price (y-axis)\n",
    "for index, feature_name in enumerate(boston.feature_names):\n",
    "    ax = f.add_subplot(5, 3, index + 1)\n",
    "    ax.scatter(boston.data[:, index], boston.target, s=0.5)\n",
    "    ax.set_title(feature_name)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** Take a look at all the scatter plots, discuss the following with your neighbor:\n",
    "1. If you can only choose one feature as predictor in the model, which one will you choose, and why?\n",
    "2. Try to find all features are that negatively correlated with price. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "Now, you will train the regression model and then use it to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Training and Test Datasets\n",
    "We can **split the dataset** into two sets so that the model can be trained and tested on different data.\n",
    "Testing accuracy is a better estimate than training accuracy of out-of-sample performance. We usually split the dataset so that the testing portion is smaller than the training portion. An 80/20 split is generally a safe bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N = len(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# check the split is successful\n",
    "print(f'{100 * X_train.shape[0] / N:0.2f}% of data in training set')\n",
    "print(f'{100 * X_test.shape[0] / N:0.2f}% of data in test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are approximately 80% training and 20% testing, so split is successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression on Boston Housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to implement the function we previously wrote on the larger boston dataset. Note that we are only using the training portion of the data so we can later evaluate our model performance using the testing data. Let's try building a model that regresses `PRICE` on to the feature that you selected in the write up earlier.\n",
    "\n",
    "**Try this!** In the following cell, set your chosen feature label (string) to the variable `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# retrieve the index of the supplied target\n",
    "target_index = boston.feature_names.tolist().index(target)\n",
    "\n",
    "# Extract feature of interest from training dataest\n",
    "X_train_target = X_train[:, target_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have isolated the target feature, let's build a model with the functions we have already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on X_train_target (training inputs) and y_train (training observations)\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "print(f'w = {w}, b = {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recycling our previous plotting code from our toy implementation, we can see our regression model against a scatter of our data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array with 1000 equally spaced values in the range 0 to x.max\n",
    "x_star = np.linspace(0, X_train_target.max(), 1000)\n",
    "\n",
    "# get the predictions for each of those values\n",
    "y_star = predict(w, b, x_star)\n",
    "\n",
    "# plot the points using a scatter plot (note this is not a line... it just looks like one)\n",
    "ax1 = plt.scatter(X_train_target, y_train)\n",
    "ax2, = plt.plot(x_star, y_star, color=\"orange\")\n",
    "plt.xlabel(target)\n",
    "plt.ylabel(\"price in 1k USD\")\n",
    "plt.ylim(0, y_star.max())\n",
    "plt.legend((ax1, ax2), ('Training data', 'Model'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** What do you think of this model? Try this process again on a different predictor (feature) and write about how it compares in the cell below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyzing Model Performance\n",
    "\n",
    "It is difficult to measure the quality of a given model without quantifying its performance over training and testing. In this section, you will see some common methods we used to evaluate the performance of a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error\n",
    "\n",
    "Recall from our derivation in lecture that our linear regression model minimizes the **residual sum of squares (RSS)**. $$\\text{RSS} = \\displaystyle \\sum_{i=1}^n (y_i - f(x_i))^2, $$where $f(x)$ is our trained model. A common way to measure model performance is to compute the scaled RSS or **mean squared error (MSE)**. $$\\text{MSE} = \\displaystyle \\frac{1}{n} \\sum_{i=1}^n (y_i - f(x_i))^2$$\n",
    "\n",
    "Taking things a step further, we can report this metric in the original units (eg. thousands of dollars) by simply taking the square root to get **root mean squared error (RMSE)**. $$\\text{RMSE} = \\displaystyle \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - f(x_i))^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, we will compute the mean of the squared differences between the actual value and the predicted value, and take the square root. The function is provided in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_test_target = X_test[:, target_index] \n",
    "\n",
    "# Predict y_pred for X_test_target (test inputs)\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate predictions\n",
    "rmse = np.sqrt(mean_squared_error(y_test, Y_pred))\n",
    "f'RMSE: {rmse}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is regarded as a measure of the quality of an estimatorâ€”it is always non-negative (we are computing squares), and values closer to zero are better (this suggests the predicted values are closer to the actual value). \n",
    "\n",
    "**Write-up!** Why do we use different datasets to train and evaluate the model? Discuss with your neighbors."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** To wrap up, let's plot our model with both our training and testing sets. Ensure that you have all the components off a nice plot, making sure to include things like axes labels, a legend, and a title. `HINT` Refer to the plotting from earlier as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "CSE217",
   "language": "python",
   "name": "cse217"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
