{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Sentiment Analysis on Movie Reviews ü§©\n",
    "\n",
    "Working on this lab should be a **collaborative effort**. We encourage you to work togheter with your group. If you do not work on your own notebook, make sure you demo to the TA/instructor as a group and share your work across the group after the lab.\n",
    "\n",
    "> Remeber, to indicate the names of your group members,if you use some of the collectivley developed code in a future homework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "1. Experience the full data science workflow from data aquisition, pre-processing, to building a model and presenting the results. \n",
    "![DSworkflow](utility/pics/DSworkflow.png)\n",
    "2. Work with free-form text data.\n",
    "3. Learn and understand two approches to sentiment analysis. \n",
    "4. Explore model evaluation techniques and analyze errors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "0. [Recap: From Buisness Problem to Sentiment Analysis](#Recap:-From-Buisness-Problem-to-Sentiment-Analysis)\n",
    "1. [Rule-Based Sentiment Prediction](#1.-Rule-Based-Sentiment-Prediction)\n",
    "    1. [Toy Example](#Toy-Example)\n",
    "    2. [Movie Reviews: Test Yourself](#Movie-Reviews:-Test-Yourself)\n",
    "    3. [Analyzing the Results](#Analyzing-the-Results)\n",
    "3. [Limitations and Introduction to Machine Learning](#2.-Limitations-and-Introduction-to-Machine-Learning)\n",
    "    1. [Quick Introduction to Sentiment Classification and Scikit-Learn](#Quick-Introduction-to-Sentiment-Classification-and-Scikit-Learn)\n",
    "    2. [Coding Task: Evaluate the Sentiment Classifier](#Coding-Task:-Evaluate-the-Sentiment-Classifier)\n",
    "    3. [Things to Try](#Things-to-Try)\n",
    "4. [Comparison](#3.-Comparison) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: From Buisness Problem to Sentiment Analysis\n",
    "\n",
    "Today we want to look at ways to help buisnesses make the most out of their customers feedback, which oftentimes comes as textual reviews or comments. Sentiment Analysis, or categorizing attitudes towards something, is quite relevant today. Amazon, for example, sells products of all sorts; those who purchase these items are able to leave reviews and comments. Besides the ratings that are given, how would a company be able to tell which products are well-liked and which ones should be removed?\n",
    "\n",
    "An easy way is through sentiment analysis, where the goal is to predict the sentiment or positivity/negativity of a product or service solely based on the text provided as comments and reviews. Throughout this lab, we will explore two different ways to predict and understand the sentiment of text data. First, we will work through a simple rule-based algorithm, looking at positive and negative words to determine the classification of reviews. Following this, we will work through a more sophisticated machine learning based approach, allowing us to scale our classification to much larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Rule-Based Sentiment Prediction\n",
    "\n",
    "Rule-based sentiment prediction is the easier of the two algorithms to learn and implement. In short, we have a list of positive words and a list of negative words, both of which will be used to calculate a \"sentiment score\" for the review.\n",
    "\n",
    "### Toy Example\n",
    "\n",
    "For example, let's say we have two sets of words, positive_words and negative_words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = ['great', 'awesome', 'happy', 'good', 'exciting', 'love']\n",
    "negative_words = ['bad', 'dislike', 'sad', 'boring', 'awful', 'poor']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a set of reviews or text that we want to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['I thought the movie was great! I was very happy I could see it.',\n",
    "           'I did not like the movie; boring acting, poor attitudes, bad lighting.',\n",
    "           'The movie was pretty exciting overall, but the sound quality was bad.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then go through each review and add or subtract to the sentiment score based on the number of positive or negative words. If there is a positive word, then we add one to the score; a negative word subtracts one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_scores = []\n",
    "for review in reviews:\n",
    "    sentiment_score = 0\n",
    "    for word in review.split(' '):\n",
    "        if word in positive_words:\n",
    "            sentiment_score += 1\n",
    "        if word in negative_words:\n",
    "            sentiment_score -= 1\n",
    "    sentiment_scores.append(sentiment_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print out these results to see the overall scores in order of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -3, 1]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do this by hand, we see that the scores don't add up correctly. Why is this? The words of the reviews are split by spaces. Take the first review for example. If we split it by spaces and look at the words, we see that the word great still has the exclamation point with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'thought', 'the', 'show', 'was', 'great!', 'I', 'was', 'very', 'happy', 'I', 'could', 'see', 'it.']\n"
     ]
    }
   ],
   "source": [
    "first_review = 'I thought the show was great! I was very happy I could see it.'\n",
    "first_review_words = first_review.split(' ')\n",
    "print(first_review_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having the words split only by spaces causes some words to include punctuation, which is something we don't want. We won't touch on this too much, but preprocessing data to make sure words or numbers are functioning correctly can increase performance and accuracy greatly. Making sure that punctuation is removed as well as standardizing to lowercase gives much more control over the text data at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'thought', 'the', 'show', 'was', 'great', 'i', 'was', 'very', 'happy', 'i', 'could', 'see', 'it']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# .lower() changes first_review to all lowercase\n",
    "# .translate(str.maketrans(input, output, delete)) will replace characters from input with respective \n",
    "#      characters in output and deletes what's in delete. \n",
    "#      --> for example: translate(str.maketrans(‚Äúaeiou‚Äù, ‚Äú12345\", \"!\")) will replace vowels with their respective \n",
    "#          numbers and deletes all exclamation marks\n",
    "# .split(' ') splits the words into an array based on ' ', or a space\n",
    "# other functions include:\n",
    "# .replace(target, new), which will replace all matches of the target string with the new string\n",
    "\n",
    "new_first_words = first_review.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \")\n",
    "print(new_first_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now re-run this code on the reviews to see the appropriate scores that should be allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3, 0]\n"
     ]
    }
   ],
   "source": [
    "sentiment_scores = []\n",
    "for review in reviews:\n",
    "    sentiment_score = 0\n",
    "    for word in review.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \"):\n",
    "        if word in positive_words:\n",
    "            sentiment_score += 1\n",
    "        if word in negative_words:\n",
    "            sentiment_score -= 1\n",
    "    sentiment_scores.append(sentiment_score)\n",
    "\n",
    "print(sentiment_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have a working function to assign sentiment scores to reviews. The final step is simply to assign a sentiment to the reviews. There are several ways to approach this, depending on what the user is attempting to do. We could work this as a Binary Classification, where each review is either positive or negative, and cannot be anything else. For this, we would assign \"Negative\" to any review with a score less than zero, and \"Positive\" to every other review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "review_sentiments = []\n",
    "\n",
    "for score in sentiment_scores:\n",
    "    if score >= 0:\n",
    "        review_sentiments.append(\"Positive\")\n",
    "    if score < 0:\n",
    "        review_sentiments.append(\"Negative\")\n",
    "        \n",
    "print(review_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we could also use Multi-class classification, including a \"Neutral\" class for the reviews that have a score of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Negative', 'Neutral']\n"
     ]
    }
   ],
   "source": [
    "review_sentiments = []\n",
    "\n",
    "for score in sentiment_scores:\n",
    "    if score > 0:\n",
    "        review_sentiments.append(\"Positive\")\n",
    "    if score < 0:\n",
    "        review_sentiments.append(\"Negative\")\n",
    "    if score == 0:\n",
    "        review_sentiments.append(\"Neutral\")\n",
    "        \n",
    "print(review_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of this in mind, there are no limits to the number of classes or splits that could be made for text data. We could adjust the range for neutral to be any reviews between -1 and 1, or perhaps add in more classes (\"Slightly Positive\", \"Slightly Negative\", \"Very Positive\", \"Very Negative\", etc...). As long as the data is preprocessed correctly and you have a good set of positive and negative words, you will be able to run sentiment analysis on the majority of text files.\n",
    "\n",
    "#### Caution!\n",
    "\n",
    "Though Rule-Based Sentiment Analysis is quick and on the easier side to implement, there are several drawbacks that can render this method inefficient. This method does not take into account misspellings, nor does it take into account context. Take the two following reviews for example.\n",
    "\n",
    "\"The movie was not good, it was bad\" and \"The movie was not bad, it was good\". \n",
    "\n",
    "Both of these reviews would end up with the same sentiment score, but are clearly different reviews. This is partly due to the nature of the method; we are only looking at one word at a time, and not pairs of words. We will not look at this specifically, but looking at pairs of words or groups of three word (called bi-grams or tri-grams or in general n-grams) can help alleviate mistakes in our analysis.\n",
    "\n",
    "Rule-Based Sentiment Analysis also does not take into account the length of the review. If we have a very long review that uses a mix of positive and negative words, it may end up being classified as something it is not. Likewise, a short but very strongly opinionated review may not receive the same sentiment as a longer, equally opinionated review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Reviews: Test Yourself\n",
    "\n",
    "In the following code blocks, work through to analyze **real-life movie reviews**! Some of the code is written for you, some will have to be filled in yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped Negative\n",
      "Unzipped Positive\n",
      "Created test folder.\n",
      "Created list of negtaive words: negative_words\n",
      "Created list of postive words: postitive_words\n"
     ]
    }
   ],
   "source": [
    "# Setup - This cell block is needed to set up everything for this testing section\n",
    "# No need to edit this cell\n",
    "\n",
    "import os\n",
    "import string\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Unzip folder with negative reviews\n",
    "if not os.path.exists('utility/data/neg'):\n",
    "    zip_ref = zipfile.ZipFile('utility/data/neg.zip', 'r')\n",
    "    zip_ref.extractall('utility/data/')\n",
    "    zip_ref.close()\n",
    "    print('Unzipped Negative')\n",
    "\n",
    "# Unzip folder with postive reviews\n",
    "if not os.path.exists('utility/data/pos'):\n",
    "    zip_ref = zipfile.ZipFile('utility/data/pos.zip', 'r')\n",
    "    zip_ref.extractall('utility/data/')\n",
    "    zip_ref.close()\n",
    "    print('Unzipped Positive')\n",
    "    \n",
    "# Create folder for testing\n",
    "pos_test = ['357_10p.txt', '347_10p.txt', '1697_10p.txt']  \n",
    "neg_test = ['1919_1n.txt', '54_1n.txt', '1819_1n.txt']  \n",
    "if not os.path.exists('utility/data/test'):\n",
    "    os.mkdir('utility/data/test')\n",
    "    shutil.copy('utility/data/pos/'+pos_test[0],'utility/data/test')\n",
    "    shutil.copy('utility/data/pos/'+pos_test[1],'utility/data/test')\n",
    "    shutil.copy('utility/data/pos/'+pos_test[2],'utility/data/test')\n",
    "\n",
    "    shutil.copy('utility/data/neg/'+neg_test[0],'utility/data/test')\n",
    "    shutil.copy('utility/data/neg/'+neg_test[1],'utility/data/test')\n",
    "    shutil.copy('utility/data/neg/'+neg_test[2],'utility/data/test')\n",
    "    print('Created test folder.')\n",
    "    \n",
    "# Create list of positive words from given file\n",
    "with open('utility/data/negative-words.txt') as f:\n",
    "    negative_words = [word.strip() for word in f.readlines() if word[0] not in [';', '\\n']]\n",
    "    print('Created list of negtaive words: negative_words')\n",
    "\n",
    "# Create list of negative words from given file\n",
    "with open('utility/data/positive-words.txt') as f:\n",
    "    positive_words = [word.strip() for word in f.readlines() if word[0] not in [';', '\\n']]\n",
    "    print('Created list of postive words: postitive_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bulk of the code will be executed in the following function. Fill in what needs to be filled in to perform rule-based sentiment prediction and test the function on a small number of reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...computing sentiment scores on utility/data/test...\n",
      "Done Running \n",
      "\n",
      "[-2, 5, 6, -6, 2, -2]\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment_scores(path2folder):\n",
    "\n",
    "    # Create a blank sentiment_scores list\n",
    "    sentiment_scores = []\n",
    "\n",
    "    print('...computing sentiment scores on '+path2folder +'...')\n",
    "\n",
    "    for file in os.listdir(path2folder):\n",
    "        path_start = path2folder + '/'\n",
    "    \n",
    "        # Create the sentiment_score variable for this review, and set it to zero\n",
    "        \n",
    "        # your code here\n",
    "        sentiment_score = 0\n",
    "    \n",
    "        with open(path_start + file, encoding = \"utf-8\") as f:\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "            # Pull the words into a words array\n",
    "            \n",
    "            # The reviews include the string \"<br />\" quite a few times; the data looks cleaner if replaced\n",
    "            # with a space!\n",
    "\n",
    "            # Hint: Remember to read, lower, replace, translate, and split!\n",
    "\n",
    "            # your code here\n",
    "            words = f.read()\n",
    "            for word in words.lower().replace(\"<br />\", \" \").translate(str.maketrans(\"\", \"\", string.punctuation)).split(\" \"):\n",
    "                if word in positive_words:\n",
    "                     sentiment_score += 1\n",
    "                if word in negative_words:\n",
    "                     sentiment_score -= 1\n",
    "            sentiment_scores.append(sentiment_score)\n",
    "\n",
    "\n",
    "            # Loop through the words to generate the sentiment score\n",
    "\n",
    "            # your code here\n",
    "\n",
    "\n",
    "            # Append the sentiment_score to the sentiment_scores array!\n",
    "\n",
    "            # your code here\n",
    "\n",
    "        \n",
    "    print('Done Running \\n')\n",
    "    f.close()\n",
    "    return sentiment_scores\n",
    "\n",
    "test_scores = get_sentiment_scores('utility/data/test')\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The results you should get for those test reviews are `[-2, 5, 6, -6, 2, -2]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the code is running correctly, perform rule-based sentiment prediction on the **_postive reviews_**! Running this function will take a little while as it needs to go through all the reviews and count the postivie and negative words in oder to get the sentiment score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...computing sentiment scores on utility/data/pos...\n",
      "Done Running \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a variable called file_path for the folder of positive reviews\n",
    "# Hint: Data is stored in the folder 'data' under 'utility', with two subfolders being 'neg' or 'pos'\n",
    "scores_pos_reviews = None\n",
    "\n",
    "# your code here\n",
    "file_path = 'utility/data/pos'\n",
    "scores_pos_reviews = get_sentiment_scores(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Results\n",
    "Now, we can see how our apporach predicts the sentiment for those reviews. This phase is a crucial part in the data science workflow and is called **model evaluation**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.40% true positive reviews (those are predicted correctly)\n",
      "15.60% false negative reviews (those are actually positive reviews)\n",
      "1688\n"
     ]
    }
   ],
   "source": [
    "# Positive Predicted Reviews:\n",
    "percent_pos = sum([1 for score in scores_pos_reviews if score >= 0]) / len(scores_pos_reviews)*100\n",
    "print(\"%.2f%% true positive reviews (those are predicted correctly)\" % (percent_pos))\n",
    "\n",
    "# Negative Predicted Reviews:\n",
    "percent_neg = sum([1 for score in scores_pos_reviews if score < 0]) / len(scores_pos_reviews)*100\n",
    "print(\"%.2f%% false negative reviews (those are actually positive reviews)\" % (percent_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these number mean? Explain whether our approach works well or not.\n",
    "\n",
    "Repeat the above computations for the **_negative reviews_** and compare the results with the ones above. Is our approach better in predictiong postivie reviews correctly or negative ones? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...computing sentiment scores on utility/data/neg...\n",
      "Done Running \n",
      "\n",
      "27.30% false positive reviews (those are actually negtaive reviews)\n",
      "72.70% true negative reviews (those are predicted correctly)\n",
      "1454\n"
     ]
    }
   ],
   "source": [
    "scores_neg_reviews = None\n",
    "\n",
    "# your code here\n",
    "\n",
    "\n",
    "# your code here\n",
    "file_path = 'utility/data/neg'\n",
    "scores_neg_reviews = get_sentiment_scores(file_path)\n",
    "\n",
    "# Positive Predcited Reviews:\n",
    "percent_pos = sum([1 for score in scores_neg_reviews if score >= 0]) / len(scores_neg_reviews)*100\n",
    "print(\"%.2f%% false positive reviews (those are actually negtaive reviews)\" % (percent_pos))\n",
    "\n",
    "# Negative Predicted Reviews:\n",
    "percent_neg = sum([1 for score in scores_neg_reviews if score < 0]) / len(scores_neg_reviews)*100\n",
    "print(\"%.2f%% true negative reviews (those are predicted correctly)\" % (percent_neg))\n",
    "print(sum([1 for score in scores_neg_reviews if score < 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the overall performance of our rule-based sentiment predictor? Compute the percentage of correctly predicted reviews over *all* reviews (this measure is also called _accuracy_), and the percentage of incorrectly predicted reviews over *all* reviews (this measure is also called _error rate_). As a sanity check, make sure both measures add up to 100%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "percent_correct = sum([1 for score in scores_neg_reviews if score < 0]) + sum([1 for score in scores_pos_reviews if score >= 0])\n",
    "percent_correct = percent_correct / (len(scores_pos_reviews) + len(scores_neg_reviews))\n",
    "percent_correct\n",
    "print(len(scores_neg_reviews))\n",
    "print(len(scores_pos_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limitations and Introduction to Machine Learning\n",
    "The rule-based sentiment predictor has many advantages including that is so simple to implement. With just a couple of extensions to our version (such as negation handling) we could actually make this production ready. However, the main drawback of this approach is that we need **hand engineered** lists of positive and negative expressions, which are non-trivial to create and also static. That means they don't adapt automatically to the domain they are being used for. For example, in formal language expressions might have different meaning than in a colloquial context. \n",
    "\n",
    "![rule-based](utility/pics/rule-based1.png)\n",
    "\n",
    "How can we overcome this problem? Can we maybe learn what expressions are used in a positive versus a negative review? The answer is '_yes - we can!_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Introduction to Sentiment Classification and Scikit-Learn\n",
    "\n",
    "Instead of working with lists of positive and negative expressions we will now look at reviews with known ratings and use thoese to learn what positive versus negative reviews are. With those known set of positive and negative reviews, we can build a model just like so: \n",
    "![machine-learning](utility/pics/ml_train1.png)\n",
    "\n",
    "And then use it on new comments and reviews to determine a customer's attitudes. This approach is a **machine learning** approach commonly know as _classification_. Just like so: \n",
    "![predict](utility/pics/ml_predict1.png)\n",
    "\n",
    "Okay, let's do it. We will be using the Scikit-Learn Python package (https://scikit-learn.org/stable/). Check [**PDSH**] Ch5 for a quick introduction to Scikit-Learn (p343-359).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 4000\n",
      "Number of words: 8870\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove test folder \n",
    "if os.path.exists('utility/data/test'):\n",
    "    shutil.rmtree('utility/data/test')  \n",
    "    \n",
    "# Load data (folders will be considered as classes (target variable) 0,1,... # subfolders)    \n",
    "data_folder = \"utility/data/\"\n",
    "dataset = load_files(data_folder, shuffle=False)\n",
    "docs_raw = dataset.data\n",
    "\n",
    "## Text preprocessing\n",
    "docs_all = []\n",
    "for doc in docs_raw:\n",
    "    docs_all.append(doc.decode('utf-8', errors='replace')) # prevent UnicodeDecodeError\n",
    "y_all = dataset.target\n",
    "\n",
    "# Text tokenizing and filtering of stopwords\n",
    "count_vect = CountVectorizer(min_df=5)  \n",
    "X_all_counts = count_vect.fit_transform(docs_all)\n",
    "\n",
    "# Number of docs and number of words\n",
    "print(\"Number of documents: \" + str(X_all_counts.shape[0])) \n",
    "print(\"Number of words: \" + str(X_all_counts.shape[1])) \n",
    "    # X_all_counts data representation (* = occurrence count):\n",
    "    #    - - - - -\n",
    "    #  |\n",
    "    #  |  *        <- document\n",
    "    #  |\n",
    "    #  |\n",
    "    #     ^\n",
    "    #    word index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After **preprocessing** the text documents, we **split** our data into two parts one for building the model (_training set_) \n",
    "and one for testing/evaluating it (_test/evaluation set_). Then we will **build the model** using the _training set_ and use the model to **predict** the sentiment of the documents in the _testing set_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 3200\n",
      "Size of the test/evaluation set: 800\n"
     ]
    }
   ],
   "source": [
    "# Split the data into two parts \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all_counts, y_all, train_size = .8, test_size = .2, random_state = 16)\n",
    "\n",
    "print(\"Size of the training set: \" + str(X_train.shape[0]))\n",
    "print(\"Size of the test/evaluation set: \" + str(X_test.shape[0]))\n",
    "\n",
    "# Build the model using a linear classification model\n",
    "model = LogisticRegression(max_iter=1000).fit(X_train,y_train)\n",
    "\n",
    "# Use the classification model for predictions\n",
    "predicted_target = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Task: Evaluate the Sentiment Classifier\n",
    "Write a function that will go through all the test data and compare the predicted class and the actual class. If an entry is put into the wrong class by the model, this function will add one to the respective variable: `fneg_error_count` if it was a _false negative_, `fpos_error_count` if it is a _false positive_. From these values you can compute  \n",
    "* the total _number of mistakes made_, \n",
    "* the _error rate_, and \n",
    "* the _accuracy_ \n",
    "\n",
    "of the machine learning approach. \n",
    "\n",
    "\n",
    "Then, this function will print out how many total errors, how many _false negatives_, and how many _false positives_ were found and the rates (which important to get the relative measure based on the number of positive/negtaive test examples). \n",
    "\n",
    "The inputs for this function are the **predicted classification** for each review generated by the model and the **actual classification** from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions(predictions, actual):\n",
    "    \n",
    "    fneg_error_count = 0\n",
    "    fpos_error_count = 0\n",
    "    \n",
    "    pos = y_test[y_test==1]\n",
    "    num_pos = pos.size\n",
    "    neg = y_test[y_test==0]\n",
    "    num_neg = neg.size\n",
    "\n",
    "    mistakes = 0\n",
    "    error_rate = 0\n",
    "    accuracy = 0\n",
    "     \n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "        \n",
    "    \n",
    "    print(\"There were a total of \" + str(mistakes) + \" errors out of \" + str(len(predictions)) + \" testpoints.\")\n",
    "    print(\"There were \" + str(fneg_error_count) + \" false negative errors\")\n",
    "    print(\"There were \" + str(fpos_error_count) + \" false positive errors\")\n",
    "    print(\"The algorithm was wrong in \" + str(error_rate) + \"% of the test cases.\" )\n",
    "    print(\"The algorithm was correct in \" + str(accuracy) + \"% of the test cases.\\n\" )\n",
    "    \n",
    "    #false negative and false postive rates\n",
    "    fnr = fneg_error_count/num_pos *100\n",
    "    fpr = fpos_error_count/num_neg *100\n",
    "    print(\"There was a %.2f%% false negative error rate.\" % fnr)\n",
    "    print(\"There was a %.2f%% false positive error rate.\" % fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can call this function using our predicted sentiments and the ground truth sentiments as input: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions(predicted_target, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Try\n",
    "* Play with the train/test split sizes. we used a 80/20 split, but you can change this and see if it has an effect on the results. \n",
    "* Play with the random seed, to create differnt train/test splits. How does this affect the results? \n",
    "* Use a different classifier, for example, NaiveBayes or a Support Vector Machine (SVM). Code examples are below - **replace** the model computation in the cell above with the respective lines to train these different models. Do these models produce different results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it turns out that this performs quite well. Of course, we can do more fancy things with the text data, instead of only counting word occurrences. \n",
    "\n",
    "[**Challenge**] In practice people also use the counts of _pairs of words_ (so-called _bi-grams_) or even _n-grams_ (counts of tuples of n words), or a feature called _TF-IDF_, which is very powerful in practice. If you still have time, check-out this tutorial explaining how to compute those: http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html. Adapt the features used, create a new train/test split, train the model again, and evaluate the performace using your new features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison \n",
    "**Group Discussion:** Compare the two apporaches **rule-based sentiment prediction** versus **sentiment classification**. What are the main differences in terms of... \n",
    "* required data?\n",
    "* quality of the results? \n",
    "* efficiency of the computation?\n",
    "* possibilities to extend the basic algorithms? \n",
    "\n",
    "Make a list of _pros_ and _cons_ for both approaches and also think of use cases/applications for either technique.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean-up\n",
    "Please run the following cell in order to clean up some of the files on your computer. While not mandatory, it will certainly save some space (over 4000 files are already unzipped, this will clear space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to clean folders (unless you want to keep several thousand text files on your computer!)\n",
    "\n",
    "if os.path.exists('utility/data/neg'):\n",
    "    shutil.rmtree('utility/data/neg')\n",
    "if os.path.exists('utility/data/pos'):\n",
    "    shutil.rmtree('utility/data/pos')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method_descriptor:\n",
      "\n",
      "translate(self, table, /)\n",
      "    Replace each character in the string using the given translation table.\n",
      "    \n",
      "      table\n",
      "        Translation table, which must be a mapping of Unicode ordinals to\n",
      "        Unicode ordinals, strings, or None.\n",
      "    \n",
      "    The table must implement lookup/indexing via __getitem__, for instance a\n",
      "    dictionary or list.  If this operation raises LookupError, the character is\n",
      "    left untouched.  Characters mapped to None are deleted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(str.translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
